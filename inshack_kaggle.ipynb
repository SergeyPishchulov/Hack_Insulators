{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7223189,"sourceType":"datasetVersion","datasetId":4181079}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#https://github.com/InsulatorData/InsulatorDataSet\n#https://universe.roboflow.com/mingrui-yu/insulatordataset-nmard/dataset/1/download - он же.","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:23.975815Z","iopub.execute_input":"2023-12-18T08:10:23.976662Z","iopub.status.idle":"2023-12-18T08:10:23.981988Z","shell.execute_reply.started":"2023-12-18T08:10:23.976616Z","shell.execute_reply":"2023-12-18T08:10:23.980867Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\nfrom torchvision.datasets import VOCDetection\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nimport os\nfrom pathlib import Path\nimport torchvision.datasets as datasets\nimport torchvision\n\nimport torch\nfrom PIL import Image\nimport numpy as np\nimport cv2\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.ops.boxes import nms\n\nfrom torchmetrics.detection.mean_ap import MeanAveragePrecision\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T09:13:09.770374Z","iopub.execute_input":"2023-12-18T09:13:09.770787Z","iopub.status.idle":"2023-12-18T09:13:12.610541Z","shell.execute_reply.started":"2023-12-18T09:13:09.770756Z","shell.execute_reply":"2023-12-18T09:13:12.609741Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = VOCDetection(str('../input/insulatordataset/InsulatorDataSet/Normal_Insulators'),year=\"2007\",image_set='train')\nval_dataset = VOCDetection(str('../input/insulatordataset/InsulatorDataSet/Normal_Insulators'),year=\"2007\",image_set='test')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.006199Z","iopub.execute_input":"2023-12-18T08:10:24.006523Z","iopub.status.idle":"2023-12-18T08:10:24.034131Z","shell.execute_reply.started":"2023-12-18T08:10:24.006479Z","shell.execute_reply":"2023-12-18T08:10:24.033123Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.035677Z","iopub.execute_input":"2023-12-18T08:10:24.036180Z","iopub.status.idle":"2023-12-18T08:10:24.042818Z","shell.execute_reply.started":"2023-12-18T08:10:24.036154Z","shell.execute_reply":"2023-12-18T08:10:24.041863Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset VOCDetection\n    Number of datapoints: 449\n    Root location: ../input/insulatordataset/InsulatorDataSet/Normal_Insulators"},"metadata":{}}]},{"cell_type":"code","source":"# from os import listdir\n# from os.path import isfile, join\n# mypath = '/home/serhio/Data/1Education/Hack_Insulators/InsulatorDataSet/Normal_Insulators/VOCdevkit/VOC2007/JPEGImages'#str(Path(os.getcwd())/'InsulatorDataSet/Normal_Insulators')\n# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n# for x in onlyfiles:\n#     print(x[:-4])","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.045676Z","iopub.execute_input":"2023-12-18T08:10:24.046373Z","iopub.status.idle":"2023-12-18T08:10:24.053235Z","shell.execute_reply.started":"2023-12-18T08:10:24.046347Z","shell.execute_reply":"2023-12-18T08:10:24.052358Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def create_model(num_classes, pretrained=False):\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrained)\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.054578Z","iopub.execute_input":"2023-12-18T08:10:24.054953Z","iopub.status.idle":"2023-12-18T08:10:24.065338Z","shell.execute_reply.started":"2023-12-18T08:10:24.054917Z","shell.execute_reply":"2023-12-18T08:10:24.064267Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"info = train_dataset[2][1]\ninfo['annotation']['object']","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.066773Z","iopub.execute_input":"2023-12-18T08:10:24.067182Z","iopub.status.idle":"2023-12-18T08:10:24.107136Z","shell.execute_reply.started":"2023-12-18T08:10:24.067113Z","shell.execute_reply":"2023-12-18T08:10:24.106048Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[{'name': 'insulator',\n  'pose': 'Unspecified',\n  'truncated': '0',\n  'difficult': '0',\n  'bndbox': {'xmin': '131', 'ymin': '333', 'xmax': '888', 'ymax': '483'}},\n {'name': 'insulator',\n  'pose': 'Unspecified',\n  'truncated': '0',\n  'difficult': '0',\n  'bndbox': {'xmin': '374', 'ymin': '542', 'xmax': '908', 'ymax': '681'}}]"},"metadata":{}}]},{"cell_type":"code","source":"def pil_to_tensor(pil_image):\n    return torch.from_numpy(np.asarray(pil_image)/255).permute(2, 0, 1).to(torch.float)\n\n\ndef info_to_dict(info):\n    boxes = []\n    objects_cnt = len(info['annotation']['object'])\n    for object_dict in info['annotation']['object']:  # ['xmin', 'ymin', 'xmax' , 'ymax']\n        # raise ValueError(object_dict)\n        bbox = [\n            int(object_dict['bndbox']['xmin']),\n            int(object_dict['bndbox']['ymin']),\n            int(object_dict['bndbox']['xmax']),\n            int(object_dict['bndbox']['ymax'])\n        ]\n        boxes.append(bbox)\n    # raise ValueError(boxes)\n    boxes = torch.Tensor(boxes).to(torch.float)\n    labels = torch.Tensor([1]*objects_cnt).to(torch.int64)\n    return {'boxes': boxes, 'labels': labels}\n\n\ninfo_to_dict(train_dataset[0][1])","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.110582Z","iopub.execute_input":"2023-12-18T08:10:24.110874Z","iopub.status.idle":"2023-12-18T08:10:24.141254Z","shell.execute_reply.started":"2023-12-18T08:10:24.110850Z","shell.execute_reply":"2023-12-18T08:10:24.140063Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'boxes': tensor([[  84.,  260., 1044.,  520.]]), 'labels': tensor([1])}"},"metadata":{}}]},{"cell_type":"code","source":"# from PIL import Image\n\n\n# def show_object_rect(image: np.ndarray, bndbox):\n#     pt1 = bndbox[:2]\n#     pt2 = bndbox[2:]\n#     image_show = image\n#     return cv2.rectangle(image_show, pt1, pt2, (0, 255, 255), 2)\n\n\n# def show_object_name(image: np.ndarray, name: str, p_tl):\n#     return cv2.putText(image, name, p_tl, 1, 1, (255, 0, 0))\n\n\n# voc_trainset = ds\n# for i, sample in enumerate(voc_trainset, 1):\n#     image, annotation = sample[0], sample[1]['annotation']\n#     objects = annotation['object']\n#     show_image = np.array(image)\n#     # print('{} object:{}'.format(i, len(objects)))\n#     if not isinstance(objects, list):\n#         object_name = objects['name']\n#         object_bndbox = objects['bndbox']\n#         x_min = int(object_bndbox['xmin'])\n#         y_min = int(object_bndbox['ymin'])\n#         x_max = int(object_bndbox['xmax'])\n#         y_max = int(object_bndbox['ymax'])\n#         show_image = show_object_rect(show_image, (x_min, y_min, x_max, y_max))\n#         show_image = show_object_name(show_image, object_name, (x_min, y_min))\n#     else:\n#         for j in objects:\n#             object_name = j['name']\n#             object_bndbox = j['bndbox']\n#             x_min = int(object_bndbox['xmin'])\n#             y_min = int(object_bndbox['ymin'])\n#             x_max = int(object_bndbox['xmax'])\n#             y_max = int(object_bndbox['ymax'])\n#             show_image = show_object_rect(\n#                 show_image, (x_min, y_min, x_max, y_max))\n#             show_image = show_object_name(\n#                 show_image, object_name, (x_min, y_min))\n\n#     # Image.fromarray(show_image).show()\n#     # img = cv2.cvtColor(show_image, cv2.COLOR_BGR2RGB)\n#     # im_pil = Image.fromarray(img)\n#     # im_pil.show()\n#     cv2.imshow('image', show_image)\n#     cv2.waitKey(0)\n\n\n# print(voc_trainset)\n# print('Down load ok')","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.142726Z","iopub.execute_input":"2023-12-18T08:10:24.143466Z","iopub.status.idle":"2023-12-18T08:10:24.150325Z","shell.execute_reply.started":"2023-12-18T08:10:24.143430Z","shell.execute_reply":"2023-12-18T08:10:24.149267Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.151715Z","iopub.execute_input":"2023-12-18T08:10:24.152085Z","iopub.status.idle":"2023-12-18T08:10:24.172589Z","shell.execute_reply.started":"2023-12-18T08:10:24.152050Z","shell.execute_reply":"2023-12-18T08:10:24.171603Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = create_model(num_classes=2, pretrained=False).to(device)\n#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n\n# train_dataset = MyDataset(df_train, '/content/table-detection-dataset/images')\n# val_dataset = MyDataset(df_val, '/content/table-detection-dataset/images')\n\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size=3,\n    shuffle=True,\n    collate_fn=collate_fn\n)\n\nval_data_loader = DataLoader(\n    val_dataset,\n    batch_size=3,\n    shuffle=False,\n    collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.174113Z","iopub.execute_input":"2023-12-18T08:10:24.174622Z","iopub.status.idle":"2023-12-18T08:10:24.830055Z","shell.execute_reply.started":"2023-12-18T08:10:24.174581Z","shell.execute_reply":"2023-12-18T08:10:24.829245Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(train_dataloader): \n    model.train()\n    running_loss = 0\n    for i, data in enumerate(train_dataloader):\n        optimizer.zero_grad()\n        images, targets = data[0], data[1]\n        images = map(pil_to_tensor, images)\n        targets = map(info_to_dict, targets)\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        loss_dict = model(images, targets)\n        loss = sum(loss for loss in loss_dict.values())\n        running_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        if i % 50 == 0:\n            print(f\"\\tИтерация (батч) #{i} loss: {loss}\")\n    train_loss = running_loss/len(train_dataloader.dataset)\n    return train_loss\n\ndef val(val_dataloader):\n    running_loss = 0\n    for data in val_dataloader:\n        optimizer.zero_grad()\n        images, targets = data[0], data[1]\n        images = map(pil_to_tensor, images)\n        targets = map(info_to_dict, targets)\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        with torch.no_grad():\n            loss_dict = model(images, targets)\n        loss_dict = model(images, targets)\n        loss = sum(loss for loss in loss_dict.values())\n        running_loss += loss.item()\n    val_loss = running_loss/len(val_dataloader.dataset)\n    return val_loss ","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.831278Z","iopub.execute_input":"2023-12-18T08:10:24.831637Z","iopub.status.idle":"2023-12-18T08:10:24.844195Z","shell.execute_reply.started":"2023-12-18T08:10:24.831605Z","shell.execute_reply":"2023-12-18T08:10:24.843287Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import time\n\n\ntrain_losses = []\nval_losses = []\ntry:\n    for epoch in range(20):\n        start = time.time()\n        train_loss = train(train_data_loader)\n        val_loss = val(val_data_loader)\n        scheduler.step()\n        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n        end = time.time()\n        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n#         metric = MeanAveragePrecision()\n#         metric.update(preds, target)\nexcept KeyboardInterrupt:\n    print('Прервано пользователем')","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:24.845932Z","iopub.execute_input":"2023-12-18T08:10:24.846578Z","iopub.status.idle":"2023-12-18T08:10:35.476378Z","shell.execute_reply.started":"2023-12-18T08:10:24.846541Z","shell.execute_reply":"2023-12-18T08:10:35.475464Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"\tИтерация (батч) #0 loss: 1.5965864658355713\nПрервано пользователем\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:35.479511Z","iopub.execute_input":"2023-12-18T08:10:35.479812Z","iopub.status.idle":"2023-12-18T08:10:35.484171Z","shell.execute_reply.started":"2023-12-18T08:10:35.479785Z","shell.execute_reply":"2023-12-18T08:10:35.483284Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_losses","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:35.485438Z","iopub.execute_input":"2023-12-18T08:10:35.485769Z","iopub.status.idle":"2023-12-18T08:10:35.499392Z","shell.execute_reply.started":"2023-12-18T08:10:35.485736Z","shell.execute_reply":"2023-12-18T08:10:35.498522Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"fig, ax  = plt.subplots()\nax.plot(train_losses, label='Train')\nax.plot(val_losses, label='Val')\nax.set(xlabel='Epoch', ylabel='Loss')\nax.legend()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:35.500567Z","iopub.execute_input":"2023-12-18T08:10:35.502495Z","iopub.status.idle":"2023-12-18T08:10:35.792319Z","shell.execute_reply.started":"2023-12-18T08:10:35.502450Z","shell.execute_reply":"2023-12-18T08:10:35.791398Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7826882c5780>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# def draw_predict(df_index, iou_threshold=0.1, threshold=0.8, scale_percent=25):\n#     model.eval()\n#     img = cv2.imread(os.path.join('/content/table-detection-dataset/images',\n#                                   df_val.loc[df_index, 'filename']))\n#     img_ = img / 255.\n#     img_ = torch.from_numpy(img_).permute(2, 0, 1).unsqueeze(0).to(torch.float).to(device)\n#     predict = model(img_)\n#     ind = nms(predict[0]['boxes'], predict[0]['scores'], iou_threshold).detach().cpu().numpy()\n#     for i, box in enumerate(predict[0]['boxes'][ind]):\n#         if predict[0]['scores'][i] > threshold:\n#             cv2.rectangle(img, \n#                     (int(box[0]), int(box[1])), \n#                     (int(box[2]), int(box[3])), \n#                     (255, 0, 0), 5)\n#     width = int(img.shape[1] * scale_percent / 100)\n#     height = int(img.shape[0] * scale_percent / 100)\n#     dim = (width, height)   \n#     img = cv2.resize(img, dim)\n#     cv2_imshow(img)\n# draw_predict(63, 0.1)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:35.793442Z","iopub.execute_input":"2023-12-18T08:10:35.793712Z","iopub.status.idle":"2023-12-18T08:10:35.798861Z","shell.execute_reply.started":"2023-12-18T08:10:35.793688Z","shell.execute_reply":"2023-12-18T08:10:35.797876Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"iou_threshold=0.1\nthreshold=0.8\nscale_percent=75\ndef draw(obj):\n    model.eval()\n    img_pil, info = obj\n    img = np.asarray(img_pil)\n    img_ = img/ 255.\n    img_ = torch.from_numpy(img_).permute(2, 0, 1).unsqueeze(0).to(torch.float).to(device)\n    predict = model(img_)\n    ind = nms(predict[0]['boxes'], predict[0]['scores'], iou_threshold).detach().cpu().numpy()\n    for i, box in enumerate(predict[0]['boxes'][ind]):\n            if predict[0]['scores'][i] > threshold:\n                cv2.rectangle(img, \n                        (int(box[0]), int(box[1])), \n                        (int(box[2]), int(box[3])), \n                        (255, 0, 0), 5)\n    width = int(img.shape[1] * scale_percent / 100)\n    height = int(img.shape[0] * scale_percent / 100)\n    dim = (width, height)   \n    img = cv2.resize(img, dim)\n    # cv2_imshow(img)\n    PIL_image = Image.fromarray(img.astype('uint8'), 'RGB')\n    PIL_image.show()\n    return PIL_image\n\nfrom IPython.display import display\nfor x in range(5):\n    display(draw(val_dataset[x]))","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:10:45.293187Z","iopub.execute_input":"2023-12-18T08:10:45.293681Z","iopub.status.idle":"2023-12-18T08:10:45.300571Z","shell.execute_reply.started":"2023-12-18T08:10:45.293638Z","shell.execute_reply":"2023-12-18T08:10:45.299584Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:23:24.478608Z","iopub.execute_input":"2023-12-18T08:23:24.479377Z","iopub.status.idle":"2023-12-18T08:23:24.488919Z","shell.execute_reply.started":"2023-12-18T08:23:24.479345Z","shell.execute_reply":"2023-12-18T08:23:24.487970Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"FasterRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=1e-05)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=1e-05)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (layer_blocks): ModuleList(\n        (0-3): 4 x Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (extra_blocks): LastLevelMaxPool()\n    )\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}