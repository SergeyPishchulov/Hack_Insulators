{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/InsulatorData/InsulatorDataSet\n",
    "#https://universe.roboflow.com/mingrui-yu/insulatordataset-nmard/dataset/1/download - он же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from torchvision.datasets import VOCDetection\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VOCDetection(str(Path(os.getcwd())/'InsulatorDataSet/Normal_Insulators'),year=\"2007\",image_set='train')\n",
    "val_dataset = VOCDetection(str(Path(os.getcwd())/'InsulatorDataSet/Normal_Insulators'),year=\"2007\",image_set='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset VOCDetection\n",
       "    Number of datapoints: 449\n",
       "    Root location: /home/serhio/Data/1Education/Hack_Insulators/InsulatorDataSet/Normal_Insulators"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# mypath = '/home/serhio/Data/1Education/Hack_Insulators/InsulatorDataSet/Normal_Insulators/VOCdevkit/VOC2007/JPEGImages'#str(Path(os.getcwd())/'InsulatorDataSet/Normal_Insulators')\n",
    "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "# for x in onlyfiles:\n",
    "#     print(x[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, pretrained=False):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrained)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'insulator',\n",
       "  'pose': 'Unspecified',\n",
       "  'truncated': '0',\n",
       "  'difficult': '0',\n",
       "  'bndbox': {'xmin': '131', 'ymin': '333', 'xmax': '888', 'ymax': '483'}},\n",
       " {'name': 'insulator',\n",
       "  'pose': 'Unspecified',\n",
       "  'truncated': '0',\n",
       "  'difficult': '0',\n",
       "  'bndbox': {'xmin': '374', 'ymin': '542', 'xmax': '908', 'ymax': '681'}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = train_dataset[2][1]\n",
    "info['annotation']['object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[  84.,  260., 1044.,  520.]]), 'labels': tensor([1])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pil_to_tensor(pil_image):\n",
    "    return torch.from_numpy(np.asarray(pil_image)/255).permute(2, 0, 1).to(torch.float)\n",
    "\n",
    "\n",
    "def info_to_dict(info):\n",
    "    boxes = []\n",
    "    objects_cnt = len(info['annotation']['object'])\n",
    "    for object_dict in info['annotation']['object']:  # ['xmin', 'ymin', 'xmax' , 'ymax']\n",
    "        # raise ValueError(object_dict)\n",
    "        bbox = [\n",
    "            int(object_dict['bndbox']['xmin']),\n",
    "            int(object_dict['bndbox']['ymin']),\n",
    "            int(object_dict['bndbox']['xmax']),\n",
    "            int(object_dict['bndbox']['ymax'])\n",
    "        ]\n",
    "        boxes.append(bbox)\n",
    "    # raise ValueError(boxes)\n",
    "    boxes = torch.Tensor(boxes).to(torch.float)\n",
    "    labels = torch.Tensor([1]*objects_cnt).to(torch.int64)\n",
    "    return {'boxes': boxes, 'labels': labels}\n",
    "\n",
    "\n",
    "info_to_dict(train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "\n",
    "# def show_object_rect(image: np.ndarray, bndbox):\n",
    "#     pt1 = bndbox[:2]\n",
    "#     pt2 = bndbox[2:]\n",
    "#     image_show = image\n",
    "#     return cv2.rectangle(image_show, pt1, pt2, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "# def show_object_name(image: np.ndarray, name: str, p_tl):\n",
    "#     return cv2.putText(image, name, p_tl, 1, 1, (255, 0, 0))\n",
    "\n",
    "\n",
    "# voc_trainset = ds\n",
    "# for i, sample in enumerate(voc_trainset, 1):\n",
    "#     image, annotation = sample[0], sample[1]['annotation']\n",
    "#     objects = annotation['object']\n",
    "#     show_image = np.array(image)\n",
    "#     # print('{} object:{}'.format(i, len(objects)))\n",
    "#     if not isinstance(objects, list):\n",
    "#         object_name = objects['name']\n",
    "#         object_bndbox = objects['bndbox']\n",
    "#         x_min = int(object_bndbox['xmin'])\n",
    "#         y_min = int(object_bndbox['ymin'])\n",
    "#         x_max = int(object_bndbox['xmax'])\n",
    "#         y_max = int(object_bndbox['ymax'])\n",
    "#         show_image = show_object_rect(show_image, (x_min, y_min, x_max, y_max))\n",
    "#         show_image = show_object_name(show_image, object_name, (x_min, y_min))\n",
    "#     else:\n",
    "#         for j in objects:\n",
    "#             object_name = j['name']\n",
    "#             object_bndbox = j['bndbox']\n",
    "#             x_min = int(object_bndbox['xmin'])\n",
    "#             y_min = int(object_bndbox['ymin'])\n",
    "#             x_max = int(object_bndbox['xmax'])\n",
    "#             y_max = int(object_bndbox['ymax'])\n",
    "#             show_image = show_object_rect(\n",
    "#                 show_image, (x_min, y_min, x_max, y_max))\n",
    "#             show_image = show_object_name(\n",
    "#                 show_image, object_name, (x_min, y_min))\n",
    "\n",
    "#     # Image.fromarray(show_image).show()\n",
    "#     # img = cv2.cvtColor(show_image, cv2.COLOR_BGR2RGB)\n",
    "#     # im_pil = Image.fromarray(img)\n",
    "#     # im_pil.show()\n",
    "#     cv2.imshow('image', show_image)\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# print(voc_trainset)\n",
    "# print('Down load ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/serhio/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/serhio/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/serhio/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = create_model(num_classes=2, pretrained=False).to(device)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "# train_dataset = MyDataset(df_train, '/content/table-detection-dataset/images')\n",
    "# val_dataset = MyDataset(df_val, '/content/table-detection-dataset/images')\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=3,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=3,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader): \n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        images, targets = data[0], data[1]\n",
    "        images = map(pil_to_tensor, images)\n",
    "        targets = map(info_to_dict, targets)\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 2 == 0:\n",
    "            print(f\"\\tИтерация (батч) #{i} loss: {loss}\")\n",
    "    train_loss = running_loss/len(train_dataloader.dataset)\n",
    "    return train_loss\n",
    "\n",
    "def val(val_dataloader):\n",
    "    running_loss = 0\n",
    "    for data in val_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        images, targets = data[0], data[1]\n",
    "        images = map(pil_to_tensor, images)\n",
    "        targets = map(info_to_dict, targets)\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "            loss_dict = model(images, targets)\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        running_loss += loss.item()\n",
    "    val_loss = running_loss/len(val_dataloader.dataset)\n",
    "    return val_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tИтерация (батч) #0 loss: 1.584665298461914\n",
      "Прервано пользователем\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "try:\n",
    "    for epoch in range(20):\n",
    "        start = time.time()\n",
    "        train_loss = train(train_data_loader)\n",
    "        val_loss = val(val_data_loader)\n",
    "        scheduler.step()\n",
    "        print(f\"Эпоха #{epoch} train_loss: {train_loss}, val_loss: {val_loss}\")  \n",
    "        end = time.time()\n",
    "        print(f\"Потрачено {round((end - start) / 60, 1)} минут на {epoch} эпоху\")\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "except KeyboardInterrupt:\n",
    "    print('Прервано пользователем')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
